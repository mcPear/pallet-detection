{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import imutils\n",
    "import sys\n",
    "import numpy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_full = cv2.imread('full_image.jpg')\n",
    "img_bkg = cv2.imread('selected_data/background.jpg')\n",
    "img_pallet = cv2.imread('selected_data/pallet.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define showing and features functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    " cv2.imshow('image',img)\n",
    " cv2.waitKey(0)\n",
    " cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr_to_cmyk(bgr):\n",
    "    RGB_SCALE = 255\n",
    "    CMYK_SCALE = 100\n",
    "    b = bgr[0]\n",
    "    g = bgr[1]\n",
    "    r = bgr[2]\n",
    "    if (r, g, b) == (0, 0, 0):\n",
    "        return 0, 0, 0, CMYK_SCALE\n",
    "\n",
    "    c = 1 - r / RGB_SCALE\n",
    "    m = 1 - g / RGB_SCALE\n",
    "    y = 1 - b / RGB_SCALE\n",
    "\n",
    "    min_cmy = min(c, m, y)\n",
    "    c = (c - min_cmy) / (1 - min_cmy)\n",
    "    m = (m - min_cmy) / (1 - min_cmy)\n",
    "    y = (y - min_cmy) / (1 - min_cmy)\n",
    "    k = min_cmy\n",
    "\n",
    "    return [c, m, y, k]\n",
    "\n",
    "def flatten(img):\n",
    "    return np.reshape(img, (img.shape[0]*img.shape[1],img.shape[2]))\n",
    "\n",
    "def features(bgr, channels, filter_white=True):\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    cmyk = np.apply_along_axis(bgr_to_cmyk, 2, bgr)\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    hsv_flat = flatten(hsv)\n",
    "    lab_flat = flatten(lab)\n",
    "    cmyk_flat = flatten(cmyk)\n",
    "    bgr_flat = flatten(bgr)\n",
    "    \n",
    "    f = np.concatenate((bgr_flat, hsv_flat, cmyk_flat, lab_flat),1)\n",
    "    f = [x for x in f if not np.sum(x[:3] == [255,255,255]) == 3] #remove white pixels\n",
    "    f = np.array(f)\n",
    "    channels_map = {'B':0, 'G':1,'R':2,'H':3,'S':4,'V':5,'C':6,'M':7,'Y':8,'K':9,'L':10,'A':11,'b':12}\n",
    "    channels = list(channels)\n",
    "    channels = [channels_map[ch] for ch in channels]\n",
    "    f = f[:,channels]\n",
    "    return np.array(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features (channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = \"HSCMYb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_full_features = features(img_full, channels)\n",
    "img_bkg_features = features(img_bkg, channels)\n",
    "img_pallet_features = features(img_pallet, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((img_bkg_features, img_pallet_features))\n",
    "y = np.concatenate(([0]*len(img_bkg_features), [1]*len(img_pallet_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "      \n",
    "train_index, test_index = sss.split(X, y).__next__()\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes - train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[600053, 190177],\n",
       "       [183785, 311439]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred=gnb.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - train and test (slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12887468 0.13561565 0.13638794 0.20813514 0.23945653 0.15153006]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[682104, 108126],\n",
       "       [188143, 307081]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=0)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred=clf.predict(X_test)\n",
    "# print(clf.feature_importances_)\n",
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "percentile = 80 # percentil, with rows we accept as pallets (with more black pixel than in other rows)\n",
    "frame = 10 # we decice that row is important if it neighbours in frame are also in percentil\n",
    "threshold = 5 # threshold of neihtbours in frame in detecting important rows\n",
    "border_size = 10 # we detecting groups of important rows (mayby pallet), \n",
    "                        #this parameter is maximal space between rows\n",
    "\n",
    "def get_pallet_sectors(img):\n",
    "    hist = [255 - np.mean(row) for row in img]\n",
    "    perc = np.percentile(hist, percentile)\n",
    "    hist_perc = [max(x - perc, 0) for x in hist]\n",
    "\n",
    "    def check_frame(row_id, image):\n",
    "        return np.count_nonzero(image[row_id: row_id + frame]) > threshold\n",
    "\n",
    "    detection = [ row_id for row_id, value in enumerate(hist_perc) if check_frame(row_id, hist_perc) ]\n",
    "\n",
    "    def check_row(list_id, rows):\n",
    "        if list_id == len(rows) -1 :\n",
    "            return rows[list_id] - rows[list_id - 1] < border_size\n",
    "        if list_id == 0:\n",
    "            return rows[list_id + 1] - rows[list_id] < border_size\n",
    "        return rows[list_id] - rows[list_id - 1] > border_size or rows[list_id + 1] - rows[list_id] > border_size\n",
    "        \n",
    "    borders = [x for x_id, x in enumerate(detection) if check_row(x_id, detection)]\n",
    "    up = borders[-2] - 4\n",
    "    bottom = borders[-1] + 4\n",
    "    return up, bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect(img, model):\n",
    "    w,h,ch = img.shape\n",
    "    f = features(img, channels, False)\n",
    "    pred = model.predict(f)\n",
    "    img_pred = np.reshape(pred, (w,h,1))\n",
    "    return np.logical_not(img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img):\n",
    "    kernel = np.ones((5,5),np.float32)/25\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return cv2.threshold(img,0.5,1.0,cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rotate(img, angle):\n",
    "    return  imutils.rotate(img, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pallet_by_height(img, mask_height):\n",
    "    mask_height = mask_height\n",
    "    mask_width = int(mask_height * 5.556)\n",
    "    mask_size = mask_height * mask_width\n",
    "    hole_height = int(mask_height * 0.694)\n",
    "    hole_width = int(mask_height * 1.58)\n",
    "    hole_size = hole_height * hole_width\n",
    "    hole_1_x = int(mask_height * 0.694)\n",
    "    hole_1_y = int(mask_height * 0.306)\n",
    "    hole_2_x = int(mask_height * 3.281)\n",
    "    hole_2_y = hole_1_y\n",
    "    best = (None, 0, (0,0))\n",
    "    inverse_img = np.logical_not(img)\n",
    "    img_height, img_width = inverse_img.shape\n",
    "    for index, x in np.ndenumerate(inverse_img):\n",
    "        x,y = index\n",
    "        if y+mask_height < img_height and x+mask_width < img_width:\n",
    "            frame_mask = inverse_img[y:y+mask_height, x:x+mask_width]\n",
    "            hole_1_y_ = y+hole_1_y\n",
    "            hole_2_y_ = y+hole_2_y\n",
    "            hole_1_x_ = x+hole_1_x\n",
    "            hole_2_x_ = x+hole_2_x\n",
    "            hole_1_mask = inverse_img[hole_1_y_:hole_1_y_+hole_height, hole_1_x_:hole_1_x_+hole_width]\n",
    "            hole_2_mask = inverse_img[hole_2_y_:hole_2_y_+hole_height, hole_2_x_:hole_2_x_+hole_width]\n",
    "            frame_mask_perc = np.sum(frame_mask) / mask_size\n",
    "            hole_1_mask_perc = np.sum(hole_1_mask) / hole_size\n",
    "            hole_2_mask_perc = np.sum(hole_2_mask) / hole_size\n",
    "            perc = frame_mask_perc - hole_1_mask_perc - hole_2_mask_perc\n",
    "            if perc >= best[1]:\n",
    "                best = (frame_mask, perc, (x,y))\n",
    "    return best\n",
    "\n",
    "def find_pallet(img, min_height, max_height, step):\n",
    "    best = (None, 0, (0,0,0))\n",
    "    for mask_height in range(min_height, max_height, step):\n",
    "        (best_for_height, perc, (x,y)) = find_pallet_by_height(img, mask_height)\n",
    "        if perc >= best[1]:\n",
    "            print(mask_height)\n",
    "            best = (best_for_height, perc, (x,y,mask_height))\n",
    "    \n",
    "    return (np.logical_not(best[0]), best[2])\n",
    "\n",
    "def draw_pallet(img_full,x,y,mask_height):\n",
    "    print(x,y)\n",
    "    mask_width = int(mask_height * 5.556)\n",
    "    color = (0,255,0)\n",
    "    img_full[y:y+mask_height, x:x+1]=color\n",
    "    img_full[y:y+mask_height, x+mask_width-1:x+mask_width]=color\n",
    "    img_full[y:y+1, x:x+mask_width]=color\n",
    "    img_full[y+mask_height-1:y+mask_height, x:x+mask_width]=color\n",
    "    return img_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(img, file, binary=True):\n",
    "    res = cv2.imwrite(file, img * 255 if binary else img)\n",
    "    print(\"saved\" if res else \"save error\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved img_classified.jpg\n",
      "saved img_filtered.jpg\n",
      "saved img_rotated.jpg\n",
      "15 (241, 317)\n",
      "saved img_pallet.jpg\n",
      "28 40\n",
      "saved img_full_marked.jpg\n"
     ]
    }
   ],
   "source": [
    "img_full = cv2.imread('r_3_272.jpg') #r_1_26.jpg\n",
    "\n",
    "img_classified = detect(img_full, clf).astype('float32')\n",
    "save(img_classified, \"img_classified.jpg\")\n",
    "\n",
    "img_filtered = median_filter(img_classified)\n",
    "save(img_filtered, \"img_filtered.jpg\")\n",
    "\n",
    "img_rotated = rotate(img_filtered, -2)\n",
    "save(img_rotated, \"img_rotated.jpg\")\n",
    "\n",
    "img_pallet, (x,y,mask_height) = find_pallet(img_rotated, 15, 30, 3)\n",
    "save(img_pallet, \"img_pallet.jpg\")\n",
    "\n",
    "img_full_marked = draw_pallet(img_full,x,y,mask_height)\n",
    "save(img_full_marked, \"img_full_marked.jpg\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localise(path,filename):\n",
    "    img_full = cv2.imread(path+\"/\"+filename)\n",
    "    img_classified = detect(img_full, clf).astype('float32')\n",
    "    img_filtered = median_filter(img_classified)\n",
    "    img_rotated = rotate(img_filtered, -2)\n",
    "    img_pallet, (x,y,mask_height) = find_pallet(img_rotated, 15, 90, 3)\n",
    "    img_full_marked = draw_pallet(img_full,x,y,mask_height)\n",
    "    save(img_full_marked, path+\"/localised/\"+filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/595 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_0.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/595 [01:48<17:57:04, 108.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_0.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_1.jpg\n",
      "15\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/595 [03:31<17:36:34, 106.90s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470 2\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_1.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_10.jpg\n",
      "15\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 3/595 [05:15<17:27:07, 106.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 2\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_10.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_11.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 4/595 [06:56<17:09:30, 104.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 250\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_11.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_12.jpg\n",
      "15\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 5/595 [08:39<17:04:43, 104.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 250\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_12.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_13.jpg\n",
      "15\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 6/595 [10:22<16:58:02, 103.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 251\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_13.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_14.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 7/595 [12:07<17:00:35, 104.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 211\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_14.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_15.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 8/595 [13:46<16:44:39, 102.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 265\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_15.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_16.jpg\n",
      "15\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 9/595 [15:27<16:36:02, 101.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 267\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_16.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_17.jpg\n",
      "15\n",
      "18\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 10/595 [17:10<16:37:52, 102.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 261\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_17.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_18.jpg\n",
      "15\n",
      "18\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 11/595 [18:57<16:49:01, 103.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323 284\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_18.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_19.jpg\n",
      "15\n",
      "21\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 12/595 [20:48<17:10:07, 106.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 293\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_19.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_2.jpg\n",
      "15\n",
      "18\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 13/595 [22:40<17:24:18, 107.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_2.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_20.jpg\n",
      "15\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 14/595 [24:32<17:36:27, 109.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_20.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_21.jpg\n",
      "15\n",
      "18\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 15/595 [26:23<17:40:01, 109.66s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_21.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_22.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 16/595 [28:07<17:21:19, 107.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368 329\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_22.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_23.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 17/595 [29:47<16:57:40, 105.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_23.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_24.jpg\n",
      "15\n",
      "18\n",
      "24\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 18/595 [31:33<16:55:17, 105.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_24.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_25.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 19/595 [33:29<17:25:31, 108.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_25.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_26.jpg\n",
      "15\n",
      "18\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 20/595 [35:33<18:05:21, 113.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 1\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_26.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_27.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 21/595 [37:32<18:20:45, 115.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 293\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_27.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_28.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "30\n",
      "33\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 22/595 [39:29<18:24:10, 115.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 303\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_28.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_29.jpg\n",
      "15\n",
      "21\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 23/595 [41:26<18:26:02, 116.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 286\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_29.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_3.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 24/595 [43:25<18:33:46, 117.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 220\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_3.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_30.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 25/595 [45:25<18:39:31, 117.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_30.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_31.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 26/595 [47:21<18:33:18, 117.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_31.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_32.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 27/595 [49:18<18:29:10, 117.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_32.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_33.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 28/595 [51:24<18:50:55, 119.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_33.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_34.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 29/595 [53:22<18:46:35, 119.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_34.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_35.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 30/595 [55:29<19:04:02, 121.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_35.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_36.jpg\n",
      "15\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 31/595 [57:26<18:50:28, 120.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 2\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_36.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_37.jpg\n",
      "15\n",
      "18\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 32/595 [59:38<19:21:00, 123.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_37.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_38.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 33/595 [1:01:37<19:04:40, 122.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 2\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_38.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_39.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 34/595 [1:03:35<18:53:05, 121.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 286\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_39.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_4.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 35/595 [1:05:34<18:42:52, 120.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 253\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_4.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_40.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 36/595 [1:07:28<18:23:55, 118.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 11\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_40.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_41.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 37/595 [1:09:10<17:37:43, 113.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 266\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_41.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_42.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 38/595 [1:10:57<17:16:15, 111.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 279\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_42.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_43.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 39/595 [1:12:37<16:41:35, 108.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 275\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_43.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_44.jpg\n",
      "15\n",
      "18\n",
      "24\n",
      "27\n",
      "30\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 40/595 [1:14:17<16:18:12, 105.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 290\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_44.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_45.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 41/595 [1:16:04<16:19:25, 106.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 314\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_45.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_46.jpg\n",
      "15\n",
      "21\n",
      "24\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 42/595 [1:17:47<16:08:09, 105.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 342\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_46.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_47.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 43/595 [1:19:35<16:15:14, 106.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_47.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_48.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 44/595 [1:21:18<16:04:32, 105.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_48.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_49.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 45/595 [1:23:05<16:09:39, 105.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_49.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_5.jpg\n",
      "15\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 46/595 [1:24:48<15:58:40, 104.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_5.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_50.jpg\n",
      "15\n",
      "18\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 47/595 [1:26:32<15:56:30, 104.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_50.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_51.jpg\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 48/595 [1:28:14<15:46:22, 103.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 364\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_51.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_52.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 49/595 [1:30:02<15:55:01, 104.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_52.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_53.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 50/595 [1:31:43<15:44:32, 103.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_53.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_54.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▊         | 51/595 [1:33:22<15:28:06, 102.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_54.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_55.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▊         | 52/595 [1:35:01<15:16:17, 101.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_55.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_56.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 53/595 [1:36:40<15:10:15, 100.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_56.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_57.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 54/595 [1:38:25<15:20:08, 102.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_57.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_58.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 55/595 [1:40:01<15:01:17, 100.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg/localised/r_1_58.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg r_1_59.jpg\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/maciej/repos/pallet-recognition/data/jpeg\"\n",
    "filenames = [f for f in sorted(listdir(path)) if isfile(join(path, f))]\n",
    "for i in tqdm(range(len(filenames))):\n",
    "    print(path, filenames[i])\n",
    "    localise(path,filenames[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Must be todo's:\n",
    "- train on many different video frames\n",
    "- rotate frame\n",
    "  \n",
    "Improvements\n",
    "- try add new channel feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results for channels combinations (Naive Bayes)\n",
    "#all\n",
    "array([[53592,  1409],\n",
    "       [ 3527,  1784]]) #5311\n",
    "#HSCY\n",
    "array([[52410,  2591],\n",
    "       [ 1819,  3492]])\n",
    "#HSCMY\n",
    "array([[52307,  2694],\n",
    "       [ 1742,  3569]])\n",
    "#HSMY\n",
    "array([[52845,  2156],\n",
    "       [ 2697,  2614]])\n",
    "#HCMY\n",
    "array([[53081,  1920],\n",
    "       [ 3070,  2241]])\n",
    "#SCMY\n",
    "array([[51814,  3187],\n",
    "       [ 2338,  2973]])\n",
    "#HSCMYb\n",
    "array([[51265,  3736],\n",
    "       [ 1250,  4061]])\n",
    "#RGBVK psują"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
