{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import imutils\n",
    "import sys\n",
    "import numpy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "%run commons.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'naive_bayes_model.sav'\n",
    "gnb = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename_blurred = 'blurred_naive_bayes_model.sav'\n",
    "gnb_blurred = pickle.load(open(filename_blurred, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sector detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "percentile = 80 # percentil, with rows we accept as pallets (with more black pixel than in other rows)\n",
    "frame = 10 # we decice that row is important if it neighbours in frame are also in percentil\n",
    "threshold = 5 # threshold of neihtbours in frame in detecting important rows\n",
    "border_size = 10 # we detecting groups of important rows (mayby pallet), \n",
    "                        #this parameter is maximal space between rows\n",
    "\n",
    "def get_pallet_sectors(img):\n",
    "    hist = [255 - np.mean(row) for row in img]\n",
    "    perc = np.percentile(hist, percentile)\n",
    "    hist_perc = [max(x - perc, 0) for x in hist]\n",
    "\n",
    "    def check_frame(row_id, image):\n",
    "        return np.count_nonzero(image[row_id: row_id + frame]) > threshold\n",
    "\n",
    "    detection = [ row_id for row_id, value in enumerate(hist_perc) if check_frame(row_id, hist_perc) ]\n",
    "\n",
    "    def check_row(list_id, rows):\n",
    "        if list_id == len(rows) -1 :\n",
    "            return rows[list_id] - rows[list_id - 1] < border_size\n",
    "        if list_id == 0:\n",
    "            return rows[list_id + 1] - rows[list_id] < border_size\n",
    "        return rows[list_id] - rows[list_id - 1] > border_size or rows[list_id + 1] - rows[list_id] > border_size\n",
    "        \n",
    "    borders = [x for x_id, x in enumerate(detection) if check_row(x_id, detection)]\n",
    "    up = borders[-2] - 4\n",
    "    bottom = borders[-1] + 4\n",
    "    return up, bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    " cv2.imshow('image',img)\n",
    " cv2.waitKey(0)\n",
    " cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect(img, model):\n",
    "    w,h,ch = img.shape\n",
    "    f = features(img, channels, False)\n",
    "    pred = model.predict(f)\n",
    "    img_pred = np.reshape(pred, (w,h,1))\n",
    "    return np.logical_not(img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img):\n",
    "    kernel = np.ones((5,5),np.float32)/25\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return cv2.threshold(img,0.5,1.0,cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rotate(img, angle):\n",
    "    return  1-imutils.rotate(1-img, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd(num):\n",
    "    return (num % 3) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pallet_by_height(img, mask_height, min_perc=0.0):\n",
    "    results=[]\n",
    "    mask_height = mask_height\n",
    "    mask_width = int(mask_height * 5.556)\n",
    "    mask_size = mask_height * mask_width\n",
    "    hole_height = int(mask_height * 0.694)\n",
    "    hole_width = int(mask_height * 1.58)\n",
    "    hole_size = hole_height * hole_width\n",
    "    hole_1_x = int(mask_height * 0.694)\n",
    "    hole_1_y = int(mask_height * 0.306)\n",
    "    hole_2_x = int(mask_height * 3.281)\n",
    "    hole_2_y = hole_1_y\n",
    "    inverse_img = np.logical_not(img)\n",
    "    img_height, img_width = inverse_img.shape\n",
    "    for index, x in np.ndenumerate(inverse_img):\n",
    "        x,y = index\n",
    "        if odd(x) and odd(y) and y+mask_height < img_height and x+mask_width < img_width:\n",
    "            frame_mask = inverse_img[y:y+mask_height, x:x+mask_width]\n",
    "            hole_1_y_ = y+hole_1_y\n",
    "            hole_2_y_ = y+hole_2_y\n",
    "            hole_1_x_ = x+hole_1_x\n",
    "            hole_2_x_ = x+hole_2_x\n",
    "            hole_1_mask = inverse_img[hole_1_y_:hole_1_y_+hole_height, hole_1_x_:hole_1_x_+hole_width]\n",
    "            hole_2_mask = inverse_img[hole_2_y_:hole_2_y_+hole_height, hole_2_x_:hole_2_x_+hole_width]\n",
    "            frame_mask_perc = np.sum(frame_mask) / mask_size\n",
    "            hole_1_mask_perc = np.sum(hole_1_mask) / hole_size\n",
    "            hole_2_mask_perc = np.sum(hole_2_mask) / hole_size\n",
    "            perc = frame_mask_perc - hole_1_mask_perc - hole_2_mask_perc\n",
    "            result=(frame_mask, perc, (x,y), mask_height)\n",
    "            if perc >= min_perc:\n",
    "                results.append(result)\n",
    "    return results\n",
    "\n",
    "def find_pallet(img, min_height, max_height, step, min_perc=0.0):\n",
    "    results=[]\n",
    "    for mask_height in range(min_height, max_height, step):\n",
    "        mask_height_results = find_pallet_by_height(img, mask_height, min_perc)\n",
    "        results.extend(mask_height_results)\n",
    "    return results\n",
    "\n",
    "def draw_pallets(img_full, results):\n",
    "    color = (0,255,0)\n",
    "    for result in results:\n",
    "        (frame_mask, perc, (x,y), mask_height)=result \n",
    "        mask_width = int(mask_height * 5.556)\n",
    "        img_full[y:y+mask_height, x:x+1]=color\n",
    "        img_full[y:y+mask_height, x+mask_width-1:x+mask_width]=color\n",
    "        img_full[y:y+1, x:x+mask_width]=color\n",
    "        img_full[y+mask_height-1:y+mask_height, x:x+mask_width]=color\n",
    "    return img_full\n",
    "\n",
    "def calculate_centers(results):\n",
    "    centers=[]\n",
    "    for result in results:\n",
    "        (frame_mask, perc, (x,y), mask_height)=result \n",
    "        mask_width = int(mask_height * 5.556)\n",
    "        x = x + mask_width/2\n",
    "        y = y + mask_height/2\n",
    "        center = (x,y)\n",
    "        centers.append(center)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(img, file, binary=True):\n",
    "    res = cv2.imwrite(file, img * 255 if binary else img)\n",
    "    print(\"saved\" if res else \"save error\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MASK_WIDTH = 25\n",
    "MAX_MASK_WIDTH = 100\n",
    "MASK_WIDTH_STEP = 3\n",
    "CONF_TH = 0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoising(img, with_save):\n",
    "    img = 1-img\n",
    "    kernel = np.ones((7,7), np.uint8) \n",
    "    img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "    if with_save:\n",
    "        save(1-img_erosion, \"img_erosion.jpg\")\n",
    "    img_dilation = cv2.dilate(img_erosion, kernel, iterations=1)\n",
    "    if with_save:\n",
    "        save(1-img_dilation, \"img_dilation.jpg\")\n",
    "    return 1-img_dilation\n",
    "\n",
    "def filling(img, with_save):\n",
    "    img = 1-img\n",
    "    kernel = np.ones((7,7), np.uint8) \n",
    "    img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "    if with_save:\n",
    "        save(1-img_dilation, \"img_dilation_2.jpg\")\n",
    "    img_erosion = cv2.erode(img_dilation, kernel, iterations=1)\n",
    "    if with_save:\n",
    "        save(1-img_erosion, \"img_erosion_2.jpg\")\n",
    "    return 1-img_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved img_classified.jpg\n",
      "saved img_erosion.jpg\n",
      "saved img_dilation.jpg\n",
      "saved img_dilation_2.jpg\n",
      "saved img_erosion_2.jpg\n",
      "saved img_rotated.jpg\n",
      "Found pallets count: 11\n",
      "saved img_full_marked.jpg\n",
      "centers [(494.5, 272.0), (305.0, 270.5), (305.0, 273.5), (308.0, 267.5), (308.0, 270.5), (308.0, 273.5), (308.0, 276.5), (311.0, 270.5), (311.0, 273.5), (307.0, 272.0), (310.0, 272.0)]\n"
     ]
    }
   ],
   "source": [
    "img_full = cv2.imread('r_1_11.jpg')\n",
    "img_blurred = cv2.medianBlur(img_full, 7)\n",
    "\n",
    "img_classified = detect(img_blurred, gnb_blurred).astype('float32')\n",
    "save(img_classified, \"img_classified.jpg\")\n",
    "\n",
    "#img_filtered = median_filter(img_classified)\n",
    "#save(img_filtered, \"img_filtered.jpg\")\n",
    "img_denoised = denoising(img_classified, True)\n",
    "img_filled = filling(img_denoised, True)\n",
    "\n",
    "img_rotated = rotate(img_filled, -2)\n",
    "save(img_rotated, \"img_rotated.jpg\")\n",
    "\n",
    "results = find_pallet(img_rotated, MIN_MASK_WIDTH, MAX_MASK_WIDTH, MASK_WIDTH_STEP, CONF_TH)\n",
    "#save(img_pallet, \"img_pallet.jpg\")\n",
    "print(\"Found pallets count:\", len(results))\n",
    "\n",
    "img_full_marked = draw_pallets(img_full, results)\n",
    "save(img_full_marked, \"img_full_marked.jpg\", False)\n",
    "centers = calculate_centers(results)\n",
    "print(\"centers\", centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localise(path,filename):\n",
    "    img_full = cv2.imread(path+filename)\n",
    "    #img_blurred = cv2.medianBlur(img_full, 7)\n",
    "    img_classified = detect(img_full, gnb).astype('float32')\n",
    "    img_denoised = denoising(img_classified, False)\n",
    "    img_filled = filling(img_denoised, False)\n",
    "    #img_filtered = median_filter(img_classified)\n",
    "    img_rotated = rotate(img_filled, -2)\n",
    "    results = find_pallet(img_rotated, MIN_MASK_WIDTH, MAX_MASK_WIDTH, MASK_WIDTH_STEP, CONF_TH)\n",
    "    img_full_marked = draw_pallets(img_full, results)\n",
    "    save(img_full_marked, path+\"localised/\"+filename, False)\n",
    "    return calculate_centers(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize_all():\n",
    "    centers = dict()\n",
    "    path = \"/home/maciej/repos/pallet-recognition/data/jpeg_marked/\"\n",
    "    filenames = [f for f in sorted(listdir(path)) if isfile(join(path, f))]\n",
    "    for i in tqdm(range(len(filenames))):\n",
    "        filename = filenames[i]\n",
    "        print(path, filename)\n",
    "        centers[filename]=localise(path,filename)\n",
    "    np.save(path+\"eval/pred_centers\", centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/85 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  1%|          | 1/85 [00:16<22:37, 16.17s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_0.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|▏         | 2/85 [00:32<22:23, 16.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_1.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▎         | 3/85 [00:48<21:58, 16.08s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_10.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|▍         | 4/85 [01:04<21:46, 16.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_11.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_12.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  6%|▌         | 5/85 [01:21<21:44, 16.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_12.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_13.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  7%|▋         | 6/85 [01:37<21:38, 16.43s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_13.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_14.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  8%|▊         | 7/85 [01:54<21:24, 16.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_14.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_15.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  9%|▉         | 8/85 [02:11<21:10, 16.50s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_15.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_16.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11%|█         | 9/85 [02:27<20:55, 16.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_16.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_17.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 12%|█▏        | 10/85 [02:43<20:35, 16.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_17.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_18.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|█▎        | 11/85 [03:00<20:22, 16.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_18.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_19.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 14%|█▍        | 12/85 [03:17<20:07, 16.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_19.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|█▌        | 13/85 [03:34<19:56, 16.62s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_2.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_20.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 16%|█▋        | 14/85 [03:50<19:34, 16.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_20.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_21.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 18%|█▊        | 15/85 [04:06<19:18, 16.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_21.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_22.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 19%|█▉        | 16/85 [04:23<19:03, 16.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_22.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_23.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|██        | 17/85 [04:40<18:46, 16.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_23.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_24.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 21%|██        | 18/85 [04:56<18:30, 16.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_24.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_25.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 22%|██▏       | 19/85 [05:12<18:07, 16.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_25.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_26.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 24%|██▎       | 20/85 [05:29<17:55, 16.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_26.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_27.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|██▍       | 21/85 [05:46<17:35, 16.49s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_27.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_28.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 26%|██▌       | 22/85 [06:02<17:22, 16.55s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_28.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_29.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 27%|██▋       | 23/85 [06:20<17:20, 16.78s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_29.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 28%|██▊       | 24/85 [06:36<16:53, 16.62s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_3.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 29%|██▉       | 25/85 [06:52<16:26, 16.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_30.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_31.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 31%|███       | 26/85 [07:08<15:59, 16.26s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_31.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_32.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 32%|███▏      | 27/85 [07:23<15:34, 16.12s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_32.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_33.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 33%|███▎      | 28/85 [07:40<15:20, 16.15s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_33.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_34.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 34%|███▍      | 29/85 [07:56<15:05, 16.16s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_34.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_35.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|███▌      | 30/85 [08:12<14:55, 16.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_35.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_36.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 36%|███▋      | 31/85 [08:29<14:46, 16.42s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_36.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_37.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 38%|███▊      | 32/85 [08:46<14:29, 16.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_37.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_38.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 39%|███▉      | 33/85 [09:02<14:12, 16.39s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_38.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_39.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|████      | 34/85 [09:18<13:55, 16.39s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_39.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 41%|████      | 35/85 [09:35<13:41, 16.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_4.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_40.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 42%|████▏     | 36/85 [09:52<13:31, 16.56s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_40.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_41.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 44%|████▎     | 37/85 [10:08<13:15, 16.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_41.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_42.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|████▍     | 38/85 [10:25<12:57, 16.53s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_42.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_43.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 46%|████▌     | 39/85 [10:41<12:39, 16.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_43.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_44.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 47%|████▋     | 40/85 [10:57<12:18, 16.41s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_44.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_45.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 48%|████▊     | 41/85 [11:13<11:56, 16.29s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_45.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_46.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 49%|████▉     | 42/85 [11:29<11:37, 16.22s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_46.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_47.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 51%|█████     | 43/85 [11:46<11:23, 16.28s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_47.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_48.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 52%|█████▏    | 44/85 [12:02<11:00, 16.10s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_48.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_49.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 53%|█████▎    | 45/85 [12:19<10:55, 16.38s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_49.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 54%|█████▍    | 46/85 [12:35<10:42, 16.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_5.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_50.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 55%|█████▌    | 47/85 [12:52<10:33, 16.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_50.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_51.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 56%|█████▋    | 48/85 [13:09<10:16, 16.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_51.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_52.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 58%|█████▊    | 49/85 [13:26<10:03, 16.76s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_52.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_53.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 59%|█████▉    | 50/85 [13:43<09:46, 16.75s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_53.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_54.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 60%|██████    | 51/85 [13:59<09:28, 16.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_54.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_55.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 61%|██████    | 52/85 [14:16<09:11, 16.70s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_55.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_56.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 62%|██████▏   | 53/85 [14:33<08:56, 16.77s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_56.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_57.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 64%|██████▎   | 54/85 [14:50<08:37, 16.71s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_57.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_58.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 65%|██████▍   | 55/85 [15:06<08:20, 16.70s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_58.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_59.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 66%|██████▌   | 56/85 [15:23<08:03, 16.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_59.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_6.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 67%|██████▋   | 57/85 [15:39<07:45, 16.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_6.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_60.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 68%|██████▊   | 58/85 [15:56<07:29, 16.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_60.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_61.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 69%|██████▉   | 59/85 [16:13<07:12, 16.62s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_61.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_62.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 71%|███████   | 60/85 [16:29<06:56, 16.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_62.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_63.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 72%|███████▏  | 61/85 [16:46<06:38, 16.61s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_63.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_64.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 73%|███████▎  | 62/85 [17:02<06:22, 16.63s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_64.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_65.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 74%|███████▍  | 63/85 [17:19<06:06, 16.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_65.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_66.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 75%|███████▌  | 64/85 [17:36<05:49, 16.65s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_66.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_67.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 76%|███████▋  | 65/85 [17:53<05:33, 16.66s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_67.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 78%|███████▊  | 66/85 [18:10<05:18, 16.77s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_7.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 79%|███████▉  | 67/85 [18:26<05:01, 16.74s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_8.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_1_9.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 80%|████████  | 68/85 [18:43<04:42, 16.64s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_9.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 81%|████████  | 69/85 [18:59<04:25, 16.57s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_0.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 82%|████████▏ | 70/85 [19:16<04:08, 16.54s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_1.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_10.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 84%|████████▎ | 71/85 [19:32<03:51, 16.54s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_10.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 85%|████████▍ | 72/85 [19:49<03:34, 16.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_11.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_12.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 86%|████████▌ | 73/85 [20:05<03:18, 16.53s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_12.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_13.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 87%|████████▋ | 74/85 [20:21<03:01, 16.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_13.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_14.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 88%|████████▊ | 75/85 [20:38<02:44, 16.48s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_14.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_15.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 89%|████████▉ | 76/85 [20:54<02:27, 16.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_15.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_16.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 91%|█████████ | 77/85 [21:11<02:11, 16.44s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_16.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 92%|█████████▏| 78/85 [21:27<01:55, 16.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_2.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 93%|█████████▎| 79/85 [21:44<01:38, 16.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_3.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 94%|█████████▍| 80/85 [22:00<01:22, 16.45s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_4.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 95%|█████████▌| 81/85 [22:17<01:06, 16.50s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_5.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_6.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 96%|█████████▋| 82/85 [22:33<00:49, 16.54s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_6.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_7.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 98%|█████████▊| 83/85 [22:50<00:33, 16.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_7.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_8.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 99%|█████████▉| 84/85 [23:06<00:16, 16.52s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_8.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked/ r_2_9.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 85/85 [23:23<00:00, 16.51s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_2_9.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "localize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
