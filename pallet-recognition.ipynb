{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import imutils\n",
    "import sys\n",
    "import numpy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run commons.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'naive_bayes_model.sav'\n",
    "gnb = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sector detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "percentile = 80 # percentil, with rows we accept as pallets (with more black pixel than in other rows)\n",
    "frame = 10 # we decice that row is important if it neighbours in frame are also in percentil\n",
    "threshold = 5 # threshold of neihtbours in frame in detecting important rows\n",
    "border_size = 10 # we detecting groups of important rows (mayby pallet), \n",
    "                        #this parameter is maximal space between rows\n",
    "\n",
    "def get_pallet_sectors(img):\n",
    "    hist = [255 - np.mean(row) for row in img]\n",
    "    perc = np.percentile(hist, percentile)\n",
    "    hist_perc = [max(x - perc, 0) for x in hist]\n",
    "\n",
    "    def check_frame(row_id, image):\n",
    "        return np.count_nonzero(image[row_id: row_id + frame]) > threshold\n",
    "\n",
    "    detection = [ row_id for row_id, value in enumerate(hist_perc) if check_frame(row_id, hist_perc) ]\n",
    "\n",
    "    def check_row(list_id, rows):\n",
    "        if list_id == len(rows) -1 :\n",
    "            return rows[list_id] - rows[list_id - 1] < border_size\n",
    "        if list_id == 0:\n",
    "            return rows[list_id + 1] - rows[list_id] < border_size\n",
    "        return rows[list_id] - rows[list_id - 1] > border_size or rows[list_id + 1] - rows[list_id] > border_size\n",
    "        \n",
    "    borders = [x for x_id, x in enumerate(detection) if check_row(x_id, detection)]\n",
    "    up = borders[-2] - 4\n",
    "    bottom = borders[-1] + 4\n",
    "    return up, bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    " cv2.imshow('image',img)\n",
    " cv2.waitKey(0)\n",
    " cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect(img, model):\n",
    "    w,h,ch = img.shape\n",
    "    f = features(img, channels, False)\n",
    "    pred = model.predict(f)\n",
    "    img_pred = np.reshape(pred, (w,h,1))\n",
    "    return np.logical_not(img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img):\n",
    "    kernel = np.ones((5,5),np.float32)/25\n",
    "    img = cv2.filter2D(img,-1,kernel)\n",
    "    return cv2.threshold(img,0.5,1.0,cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rotate(img, angle):\n",
    "    return  imutils.rotate(img, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd(num):\n",
    "    return (num % 3) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pallet_by_height(img, mask_height):\n",
    "    mask_height = mask_height\n",
    "    mask_width = int(mask_height * 5.556)\n",
    "    mask_size = mask_height * mask_width\n",
    "    hole_height = int(mask_height * 0.694)\n",
    "    hole_width = int(mask_height * 1.58)\n",
    "    hole_size = hole_height * hole_width\n",
    "    hole_1_x = int(mask_height * 0.694)\n",
    "    hole_1_y = int(mask_height * 0.306)\n",
    "    hole_2_x = int(mask_height * 3.281)\n",
    "    hole_2_y = hole_1_y\n",
    "    best = (None, 0, (0,0))\n",
    "    inverse_img = np.logical_not(img)\n",
    "    img_height, img_width = inverse_img.shape\n",
    "    for index, x in np.ndenumerate(inverse_img):\n",
    "        x,y = index\n",
    "        if odd(x) and odd(y) and y+mask_height < img_height and x+mask_width < img_width:\n",
    "            frame_mask = inverse_img[y:y+mask_height, x:x+mask_width]\n",
    "            hole_1_y_ = y+hole_1_y\n",
    "            hole_2_y_ = y+hole_2_y\n",
    "            hole_1_x_ = x+hole_1_x\n",
    "            hole_2_x_ = x+hole_2_x\n",
    "            hole_1_mask = inverse_img[hole_1_y_:hole_1_y_+hole_height, hole_1_x_:hole_1_x_+hole_width]\n",
    "            hole_2_mask = inverse_img[hole_2_y_:hole_2_y_+hole_height, hole_2_x_:hole_2_x_+hole_width]\n",
    "            frame_mask_perc = np.sum(frame_mask) / mask_size\n",
    "            hole_1_mask_perc = np.sum(hole_1_mask) / hole_size\n",
    "            hole_2_mask_perc = np.sum(hole_2_mask) / hole_size\n",
    "            perc = frame_mask_perc - hole_1_mask_perc - hole_2_mask_perc\n",
    "            if perc >= best[1]:\n",
    "                best = (frame_mask, perc, (x,y))\n",
    "    return best\n",
    "\n",
    "def find_pallet(img, min_height, max_height, step, min_perc=0.0):\n",
    "    best = (None, min_perc, (0,0,0))\n",
    "    for mask_height in range(min_height, max_height, step):\n",
    "        (best_for_height, perc, (x,y)) = find_pallet_by_height(img, mask_height)\n",
    "        if perc >= best[1]:\n",
    "            print(\"height: \", mask_height, \"percent: \",perc)\n",
    "            best = (best_for_height, perc, (x,y,mask_height))\n",
    "    \n",
    "    return (np.logical_not(best[0]), best[2])\n",
    "\n",
    "def draw_pallet(img_full,x,y,mask_height):\n",
    "    print(x,y)\n",
    "    mask_width = int(mask_height * 5.556)\n",
    "    color = (0,255,0)\n",
    "    img_full[y:y+mask_height, x:x+1]=color\n",
    "    img_full[y:y+mask_height, x+mask_width-1:x+mask_width]=color\n",
    "    img_full[y:y+1, x:x+mask_width]=color\n",
    "    img_full[y+mask_height-1:y+mask_height, x:x+mask_width]=color\n",
    "    return img_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(img, file, binary=True):\n",
    "    res = cv2.imwrite(file, img * 255 if binary else img)\n",
    "    print(\"saved\" if res else \"save error\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved img_classified.jpg\n",
      "saved img_filtered.jpg\n",
      "saved img_rotated.jpg\n",
      "height:  25 percent:  0.056992589678011685\n",
      "height:  28 percent:  0.11277203272109895\n",
      "saved img_pallet.jpg\n",
      "459 279\n",
      "saved img_full_marked.jpg\n"
     ]
    }
   ],
   "source": [
    "img_full = cv2.imread('r_3_272.jpg')\n",
    "\n",
    "img_classified = detect(img_full, gnb).astype('float32')\n",
    "save(img_classified, \"img_classified.jpg\")\n",
    "\n",
    "img_filtered = median_filter(img_classified)\n",
    "save(img_filtered, \"img_filtered.jpg\")\n",
    "\n",
    "img_rotated = rotate(img_filtered, -2)\n",
    "save(img_rotated, \"img_rotated.jpg\")\n",
    "\n",
    "img_pallet, (x,y,mask_height) = find_pallet(img_rotated, 25, 100, 3)\n",
    "save(img_pallet, \"img_pallet.jpg\")\n",
    "\n",
    "img_full_marked = draw_pallet(img_full,x,y,mask_height)\n",
    "save(img_full_marked, \"img_full_marked.jpg\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((7,7), np.uint8) \n",
    "# img_erosion = cv2.erode(img_classified, kernel, iterations=1) \n",
    "# img_dilation = cv2.dilate(img_classified, kernel, iterations=1) \n",
    "# img_de = cv2.erode(img_dilation, kernel, iterations=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show(img_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localise(path,filename):\n",
    "    img_full = cv2.imread(path+\"/\"+filename)\n",
    "    img_classified = detect(img_full, gnb).astype('float32')\n",
    "    img_filtered = median_filter(img_classified)\n",
    "    img_rotated = rotate(img_filtered, -2)\n",
    "    img_pallet, (x,y,mask_height) = find_pallet(img_rotated, 25, 100, 3)\n",
    "    img_full_marked = draw_pallet(img_full,x,y,mask_height)\n",
    "    save(img_full_marked, path+\"/localised/\"+filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localize_all():\n",
    "    path = \"/home/maciej/repos/pallet-recognition/data/jpeg_marked\"\n",
    "    filenames = [f for f in sorted(listdir(path)) if isfile(join(path, f))]\n",
    "    for i in tqdm(range(len(filenames))):\n",
    "        print(path, filenames[i])\n",
    "        localise(path,filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/85 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_0.jpg\n",
      "height:  25 percent:  0.1677985441668306\n",
      "height:  28 percent:  0.2078726875840628\n",
      "height:  34 percent:  0.23839132898896387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/85 [00:16<23:09, 16.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 252\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_0.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_1.jpg\n",
      "height:  25 percent:  0.15624106498786802\n",
      "height:  28 percent:  0.21845412651864266\n",
      "height:  31 percent:  0.24165565200824016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/85 [00:34<23:22, 16.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 255\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_1.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_10.jpg\n",
      "height:  25 percent:  0.214314381270903\n",
      "height:  34 percent:  0.24843400435942795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 3/85 [00:51<23:12, 16.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 252\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_10.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_11.jpg\n",
      "height:  25 percent:  0.1809980982359499\n",
      "height:  28 percent:  0.21123189204683265\n",
      "height:  31 percent:  0.23957700734707485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 4/85 [01:08<23:03, 17.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 255\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_11.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_12.jpg\n",
      "height:  25 percent:  0.14353334644894747\n",
      "height:  28 percent:  0.14845324454832096\n",
      "height:  31 percent:  0.21829117993784167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 5/85 [01:25<22:40, 17.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 255\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_12.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_13.jpg\n",
      "height:  25 percent:  0.19582398845825955\n",
      "height:  31 percent:  0.2852171376177377\n",
      "height:  34 percent:  0.30972087751198435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 6/85 [01:42<22:17, 16.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 252\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_13.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_14.jpg\n",
      "height:  25 percent:  0.24198308085776116\n",
      "height:  31 percent:  0.24626841234118055\n",
      "height:  37 percent:  0.28493078444297965\n",
      "height:  40 percent:  0.3124670305225861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 7/85 [01:58<21:51, 16.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 258\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_14.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_15.jpg\n",
      "height:  25 percent:  0.266835858089055\n",
      "height:  28 percent:  0.2724020461711463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 8/85 [02:15<21:28, 16.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 252\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_15.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_16.jpg\n",
      "height:  25 percent:  0.17818479900321332\n",
      "height:  43 percent:  0.22364282581217623\n",
      "height:  46 percent:  0.2807677676025997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 9/85 [02:31<21:07, 16.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 258\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_16.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_17.jpg\n",
      "height:  25 percent:  0.1678746147288347\n",
      "height:  52 percent:  0.18989896028767983\n",
      "height:  55 percent:  0.2668046741468095\n",
      "height:  58 percent:  0.32294347331828593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 10/85 [02:48<20:51, 16.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 261\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_17.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_18.jpg\n",
      "height:  25 percent:  0.28702341137123744\n",
      "height:  70 percent:  0.29110294773954565\n",
      "height:  73 percent:  0.3011555673203479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 11/85 [03:05<20:29, 16.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 267\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_18.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_19.jpg\n",
      "height:  25 percent:  0.26654993770083285\n",
      "height:  28 percent:  0.26802416598681456\n",
      "height:  31 percent:  0.2849983329165625\n",
      "height:  82 percent:  0.31169034217814706\n",
      "height:  85 percent:  0.3322741630999949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 12/85 [03:21<20:10, 16.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 276\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_19.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_2.jpg\n",
      "height:  25 percent:  0.18351104990491174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 13/85 [03:38<19:56, 16.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_2.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_20.jpg\n",
      "height:  25 percent:  0.2779395370188209\n",
      "height:  28 percent:  0.3038211364187595\n",
      "height:  40 percent:  0.30813869424980533\n",
      "height:  94 percent:  0.3125358215600329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▋        | 14/85 [03:54<19:39, 16.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height:  97 percent:  0.33243352179162483\n",
      "0 288\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_20.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_21.jpg\n",
      "height:  25 percent:  0.2639097645747262\n",
      "height:  28 percent:  0.283348400326329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 15/85 [04:11<19:21, 16.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 330\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_21.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_22.jpg\n",
      "height:  25 percent:  0.22206177454259296\n",
      "height:  28 percent:  0.230077392895729\n",
      "height:  31 percent:  0.24242295692970864\n",
      "height:  58 percent:  0.24321259699820424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|█▉        | 16/85 [04:28<19:05, 16.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 342\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_22.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_23.jpg\n",
      "height:  25 percent:  0.22851334513738605\n",
      "height:  28 percent:  0.24248561285912731\n",
      "height:  31 percent:  0.24775836816346944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 17/85 [04:44<18:48, 16.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 348\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_23.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_24.jpg\n",
      "height:  25 percent:  0.2248370384943275\n",
      "height:  28 percent:  0.235940290609221\n",
      "height:  31 percent:  0.2367876195239286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██        | 18/85 [05:01<18:29, 16.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_24.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_25.jpg\n",
      "height:  25 percent:  0.21706472555577414\n",
      "height:  28 percent:  0.21876281613123721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 19/85 [05:18<18:18, 16.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_25.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_26.jpg\n",
      "height:  25 percent:  0.24101646009574396\n",
      "height:  37 percent:  0.2412724751665038\n",
      "height:  40 percent:  0.25838397921731254\n",
      "height:  55 percent:  0.26784004947036427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 20/85 [05:34<18:06, 16.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 327\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_26.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_27.jpg\n",
      "height:  25 percent:  0.24781034821955536\n",
      "height:  28 percent:  0.2697726721495822\n",
      "height:  31 percent:  0.281886691911073\n",
      "height:  37 percent:  0.29592707930807177\n",
      "height:  40 percent:  0.3148853218297663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▍       | 21/85 [05:51<17:54, 16.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 309\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_27.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_28.jpg\n",
      "height:  25 percent:  0.22380746278444488\n",
      "height:  28 percent:  0.23882874341278415\n",
      "height:  31 percent:  0.2794783517307899\n",
      "height:  34 percent:  0.31710821360991637\n",
      "height:  37 percent:  0.32292228309049165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 22/85 [06:09<17:49, 16.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 303\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_28.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_29.jpg\n",
      "height:  25 percent:  0.28132598858941565\n",
      "height:  28 percent:  0.3413974819747315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 23/85 [06:26<17:34, 17.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 285\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_29.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_3.jpg\n",
      "height:  25 percent:  0.29708308741556827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 24/85 [06:44<17:30, 17.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_3.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_30.jpg\n",
      "height:  25 percent:  0.26747327693619255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 25/85 [07:01<17:12, 17.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 279\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_30.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_31.jpg\n",
      "height:  25 percent:  0.22782608695652173\n",
      "height:  28 percent:  0.23492051242475692\n",
      "height:  31 percent:  0.235020808773622\n",
      "height:  55 percent:  0.24630867537262388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|███       | 26/85 [07:18<17:03, 17.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 264\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_31.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_32.jpg\n",
      "height:  25 percent:  0.22582464423896648\n",
      "height:  28 percent:  0.2337827707097656\n",
      "height:  40 percent:  0.24122197594419814\n",
      "height:  43 percent:  0.30014063100494237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 27/85 [07:36<16:43, 17.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 255\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_32.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_33.jpg\n",
      "height:  25 percent:  0.22100990228867468\n",
      "height:  34 percent:  0.23163824550992274\n",
      "height:  37 percent:  0.31829427408905964\n",
      "height:  40 percent:  0.32783597089152644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 28/85 [07:52<16:17, 17.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 249\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_33.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_34.jpg\n",
      "height:  25 percent:  0.223183159551446\n",
      "height:  28 percent:  0.23121403214781824\n",
      "height:  31 percent:  0.2380751437859465\n",
      "height:  34 percent:  0.29206267884075765\n",
      "height:  37 percent:  0.35497738276543994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 29/85 [08:09<15:53, 17.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_34.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_35.jpg\n",
      "height:  25 percent:  0.2323194963604171\n",
      "height:  28 percent:  0.23890701827883487\n",
      "height:  34 percent:  0.26535027377330767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 30/85 [08:25<15:11, 16.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_35.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_36.jpg\n",
      "height:  25 percent:  0.1588235294117647\n",
      "height:  28 percent:  0.23387758251934826\n",
      "height:  31 percent:  0.280273937532002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▋      | 31/85 [08:40<14:34, 16.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 246\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_36.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_37.jpg\n",
      "height:  25 percent:  0.2382202111613876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 32/85 [08:55<14:03, 15.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 0\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_37.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_38.jpg\n",
      "height:  25 percent:  0.15235228539576368\n",
      "height:  28 percent:  0.20241880360725859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███▉      | 33/85 [09:11<13:38, 15.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 207\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_38.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_39.jpg\n",
      "height:  25 percent:  0.11702800183618599\n",
      "height:  28 percent:  0.13002998699093776\n",
      "height:  31 percent:  0.16748234677717047\n",
      "height:  34 percent:  0.17651614867230472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 34/85 [09:26<13:15, 15.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 252\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_39.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_4.jpg\n",
      "height:  25 percent:  0.22819594727523113\n",
      "height:  28 percent:  0.26388772517804776\n",
      "height:  31 percent:  0.26457804927422335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 35/85 [09:41<12:56, 15.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 252\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_4.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_40.jpg\n",
      "height:  25 percent:  0.11233130041314186\n",
      "height:  28 percent:  0.1147917447577889\n",
      "height:  31 percent:  0.14779438907345885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 36/85 [09:57<12:39, 15.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 204\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_40.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_41.jpg\n",
      "height:  25 percent:  0.14892779854416682\n",
      "height:  34 percent:  0.15657286949129395\n",
      "height:  37 percent:  0.16694428659104857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▎     | 37/85 [10:12<12:20, 15.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 198\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_41.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_42.jpg\n",
      "height:  25 percent:  0.18292871663715654\n",
      "height:  55 percent:  0.19581971773435947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▍     | 38/85 [10:27<12:01, 15.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 258\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_42.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_43.jpg\n",
      "height:  25 percent:  0.20426126303364153\n",
      "height:  28 percent:  0.2193757855048178\n",
      "height:  64 percent:  0.22435428842179989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 39/85 [10:43<11:47, 15.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 264\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_43.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_44.jpg\n",
      "height:  25 percent:  0.29186438454980657\n",
      "height:  28 percent:  0.32131281282384844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 40/85 [10:58<11:32, 15.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 291\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_44.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_45.jpg\n",
      "height:  25 percent:  0.29880385599055675\n",
      "height:  40 percent:  0.3138249360471583\n",
      "height:  43 percent:  0.3166321861543334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 41/85 [11:13<11:14, 15.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 309\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_45.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_46.jpg\n",
      "height:  25 percent:  0.24427437864778018\n",
      "height:  31 percent:  0.2542629705045309\n",
      "height:  40 percent:  0.2604535090646201\n",
      "height:  43 percent:  0.2685757494897323\n",
      "height:  46 percent:  0.28317589307812885\n",
      "height:  55 percent:  0.29207361452881847\n",
      "height:  58 percent:  0.3006726032588102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████▉     | 42/85 [11:28<10:57, 15.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 333\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_46.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_47.jpg\n",
      "height:  25 percent:  0.2312453275624631\n",
      "height:  28 percent:  0.23455780212995836\n",
      "height:  31 percent:  0.23708382452756047\n",
      "height:  46 percent:  0.23988073957960937\n",
      "height:  64 percent:  0.24348528162675423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 43/85 [11:44<10:47, 15.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 357\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_47.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_48.jpg\n",
      "height:  25 percent:  0.21281920125909892\n",
      "height:  28 percent:  0.22571384472912487\n",
      "height:  31 percent:  0.23320859976898986\n",
      "height:  46 percent:  0.2400368048107509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 44/85 [12:00<10:39, 15.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 366\n",
      "saved /home/maciej/repos/pallet-recognition/data/jpeg_marked/localised/r_1_48.jpg\n",
      "/home/maciej/repos/pallet-recognition/data/jpeg_marked r_1_49.jpg\n",
      "height:  25 percent:  0.2272463768115942\n",
      "height:  28 percent:  0.23547946111613344\n"
     ]
    }
   ],
   "source": [
    "localize_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
